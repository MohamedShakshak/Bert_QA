# BERT-QA-SQuAD2 LoRA Adapter ğŸš€

[![Hugging Face Model]](https://huggingface.co/MohamedShakhsak/bert-qa-squad2_V2)

A **parameter-efficient** (LoRA) fine-tuned BERT model for **question answering** on SQuAD 2.0, achieving **45.95 F1** with only **0.8% trainable parameters** of the base model.

## Key Features âœ¨

- ğŸ—ï¸ **LoRA-optimized** - 3MB adapter for `bert-base-uncased`
- âš¡ **Efficient training** - 3hrs on single T4 GPU
- ğŸ“Š **Competitive performance** - 37.16 EM / 45.95 F1
- ï¿½ **Easy integration** - Works with Hugging Face `pipeline`

## Installation ğŸ“¦

```bash
pip install torch transformers peft accelerate evaluate
